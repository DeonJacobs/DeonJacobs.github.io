#summary(lm(Fertility~Agriculture,swiss))$coeff
#summary(lm(Fertility ~ Agriculture + factor(CatholicBin), data = swiss))$coeff
coef <- summary(lm(Fertility ~ Agriculture*factor(CatholicBin),data=swiss))$coef
g = g + geom_abline(aes(intercept=coef[1,1], slope=coef[2,1]))
g = g + geom_abline(aes(intercept=coef[1,1]+coef[3,1], slope=coef[2,1]+coef[4,1]))
g
}
source('~/Rstudio Work/Linear Regression/Multivariate_example3.R')
multi
multi()
multi()
library(dplyr)
data(swiss)
head(swiss)
g = ggplot(swiss, aes(x = Agriculture, y = Fertility, colour = factor(CatholicBin)))
g = g + geom_point(size = 6, colour = "black") + geom_point(size = 4)
g = g + xlab("% in Agriculture") + ylab("Fertility")
g = ggplot(swiss, aes(x = Agriculture, y = Fertility, colour = factor(CatholicBin)))
g = g + geom_point(size = 6, colour = "black") + geom_point(size = 4)
g = g + xlab("% in Agriculture") + ylab("Fertility")
g = ggplot(swiss, aes(x = Agriculture, y = Fertility, colour = factor(CatholicBin)))
g = g + geom_point(size = 6, colour = "black") + geom_point(size = 4)
g = g + xlab("% in Agriculture") + ylab("Fertility")
g
g = ggplot(swiss, aes(x = Agriculture, y = Fertility, colour = factor(Catholic)))
g = g + geom_point(size = 6, colour = "black") + geom_point(size = 4)
g = g + xlab("% in Agriculture") + ylab("Fertility")
g
coef <- summary(lm(Fertility ~ Agriculture*factor(CatholicBin),data=swiss))$coef
g = g + geom_abline(aes(intercept=coef[1,1], slope=coef[2,1]))
g = g + geom_abline(aes(intercept=coef[1,1]+coef[3,1], slope=coef[2,1]+coef[4,1]))
g
coef <- summary(lm(Fertility ~ Agriculture*factor(CatholicBin),data=swiss))$coef
coef <- summary(lm(Fertility ~ Agriculture*factor(Catholic),data=swiss))$coef
g = g + geom_abline(aes(intercept=coef[1,1], slope=coef[2,1]))
g = g + geom_abline(aes(intercept=coef[1,1]+coef[3,1], slope=coef[2,1]+coef[4,1]))
g
source('~/Rstudio Work/Linear Regression/Diamond_residuals_example.R')
diamon()
diamond()
library(UsingR)
library(ggplot2)
data(diamond)
y   <- diamond$price
x   <- diamond$carat
n   <- length(y)
fit <- lm(y ~ x)
e   <- resid(fit)
res_var <- summary(fit)$sigma
#Plotting the residuals
g <- ggplot(data.frame(x=x,y=resid(fit)),aes(x=x,y=y))
g <- g + geom_hline(yintercept = 0, size=2)
g <- g + geom_point(size=7, colour = "black",alpha=0.4)
g <- g + geom_point(size=5, colour = "blue", alpha=0.4)
g <- g +xlab("X") + ylab("Residual")
#g
res_var
library(UsingR)
library(ggplot2)
data(diamond)
y   <- diamond$price
x   <- diamond$carat
n   <- length(y)
fit <- lm(y ~ x)
e   <- resid(fit)
res_var <- summary(fit)$sigma
#Plotting the residuals
g <- ggplot(data.frame(x=x,y=resid(fit)),aes(x=x,y=y))
g <- g + geom_hline(yintercept = 0, size=2)
g <- g + geom_point(size=7, colour = "black",alpha=0.4)
g <- g + geom_point(size=5, colour = "blue", alpha=0.4)
g <- g +xlab("X") + ylab("Residual")
g
library(UsingR)
install.packages('Hmisc')
install.packages('Hmisc')
library(Hmisc)
library(Hmisc)
library(ggplot2)
library(UsingR)
library(ggplot2)
data(diamond)
y   <- diamond$price
x   <- diamond$carat
n   <- length(y)
fit <- lm(y ~ x)
e   <- resid(fit)
res_var <- summary(fit)$sigma
#Plotting the residuals
g <- ggplot(data.frame(x=x,y=resid(fit)),aes(x=x,y=y))
g <- g + geom_hline(yintercept = 0, size=2)
g <- g + geom_point(size=7, colour = "black",alpha=0.4)
g <- g + geom_point(size=5, colour = "blue", alpha=0.4)
g <- g +xlab("X") + ylab("Residual")
g
library(UsingR)
source('~/Rstudio Work/Linear Regression/Diamond_regression_inference.R')
Diamond()
library(Hmisc)
install.packages('Hmisc')
library(Hmisc)
library(UsingR)
data(diamond)
y <- diamond$price
x <- diamond$carat
n <- length(x)
beta1 <- cor(y,x)*sd(y)/sd(x)
beta0 <- mean(y) - beta1*mean(x)
e <- y - (beta0 + beta1*x)           #remember that the residuals are the estimates
#of the errors introduced in the model
sigma <- sqrt(sum(e^2)/(n-2))
ssx <- sum((x-mean(x))^2)
#Standard Error calculation for each of the coefficients in preparation for T statistic
seBeta0 <- (1/n + (mean(x)^2)/(ssx))^0.5*sigma  #Standard Error of Beta 0 (the linear regression parameters)
seBeta1 <-  sigma/sqrt(ssx)
#T statistic calculation from Student
tBeta0 <- beta0/seBeta0
tBeta1 <- beta1/seBeta1
#P-values of the regression linear line coefficients (Bo and B1)
pBeta0 <- 2*pt(abs(tBeta0),df=n-2,lower.tail=FALSE)     # multiplied by two since its the two sided test
pBeta1 <- 2*pt(abs(tBeta1),df=n-2,lower.tail=FALSE)
#place all metrics into a well formatted data.frame
coefTable <- rbind(c(beta0,seBeta0,tBeta0,pBeta0),c(beta1,seBeta1,tBeta1,pBeta1))
colnames(coefTable) <- c("Estimate","Std. Error","t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)","x")
#calculate coefficients using lm function
fit <- lm(y~x)
#confidence interval
sumCoef <- summary(fit)$coefficients
confIntBeta0 <- sumCoef[1,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
ConfIntBeta1 <- (sumCoef[2,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2])/10
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
g
library(UsingR)
data(diamond)
y <- diamond$price
x <- diamond$carat
n <- length(x)
beta1 <- cor(y,x)*sd(y)/sd(x)
beta0 <- mean(y) - beta1*mean(x)
e <- y - (beta0 + beta1*x)           #remember that the residuals are the estimates
#of the errors introduced in the model
sigma <- sqrt(sum(e^2)/(n-2))
ssx <- sum((x-mean(x))^2)
#Standard Error calculation for each of the coefficients in preparation for T statistic
seBeta0 <- (1/n + (mean(x)^2)/(ssx))^0.5*sigma  #Standard Error of Beta 0 (the linear regression parameters)
seBeta1 <-  sigma/sqrt(ssx)
#T statistic calculation from Student
tBeta0 <- beta0/seBeta0
tBeta1 <- beta1/seBeta1
#P-values of the regression linear line coefficients (Bo and B1)
pBeta0 <- 2*pt(abs(tBeta0),df=n-2,lower.tail=FALSE)     # multiplied by two since its the two sided test
pBeta1 <- 2*pt(abs(tBeta1),df=n-2,lower.tail=FALSE)
#place all metrics into a well formatted data.frame
coefTable <- rbind(c(beta0,seBeta0,tBeta0,pBeta0),c(beta1,seBeta1,tBeta1,pBeta1))
colnames(coefTable) <- c("Estimate","Std. Error","t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)","x")
#calculate coefficients using lm function
fit <- lm(y~x)
#confidence interval
sumCoef <- summary(fit)$coefficients
confIntBeta0 <- sumCoef[1,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
ConfIntBeta1 <- (sumCoef[2,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2])/10
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
#g
gg <- ggploty(g)
library(UsingR)
library(plotly)
data(diamond)
y <- diamond$price
x <- diamond$carat
n <- length(x)
beta1 <- cor(y,x)*sd(y)/sd(x)
beta0 <- mean(y) - beta1*mean(x)
e <- y - (beta0 + beta1*x)           #remember that the residuals are the estimates
#of the errors introduced in the model
sigma <- sqrt(sum(e^2)/(n-2))
ssx <- sum((x-mean(x))^2)
#Standard Error calculation for each of the coefficients in preparation for T statistic
seBeta0 <- (1/n + (mean(x)^2)/(ssx))^0.5*sigma  #Standard Error of Beta 0 (the linear regression parameters)
seBeta1 <-  sigma/sqrt(ssx)
#T statistic calculation from Student
tBeta0 <- beta0/seBeta0
tBeta1 <- beta1/seBeta1
#P-values of the regression linear line coefficients (Bo and B1)
pBeta0 <- 2*pt(abs(tBeta0),df=n-2,lower.tail=FALSE)     # multiplied by two since its the two sided test
pBeta1 <- 2*pt(abs(tBeta1),df=n-2,lower.tail=FALSE)
#place all metrics into a well formatted data.frame
coefTable <- rbind(c(beta0,seBeta0,tBeta0,pBeta0),c(beta1,seBeta1,tBeta1,pBeta1))
colnames(coefTable) <- c("Estimate","Std. Error","t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)","x")
#calculate coefficients using lm function
fit <- lm(y~x)
#confidence interval
sumCoef <- summary(fit)$coefficients
confIntBeta0 <- sumCoef[1,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
ConfIntBeta1 <- (sumCoef[2,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2])/10
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
#g
gg <- ggploty(g)
library(UsingR)
library(plotly)
data(diamond)
y <- diamond$price
x <- diamond$carat
n <- length(x)
beta1 <- cor(y,x)*sd(y)/sd(x)
beta0 <- mean(y) - beta1*mean(x)
e <- y - (beta0 + beta1*x)           #remember that the residuals are the estimates
#of the errors introduced in the model
sigma <- sqrt(sum(e^2)/(n-2))
ssx <- sum((x-mean(x))^2)
#Standard Error calculation for each of the coefficients in preparation for T statistic
seBeta0 <- (1/n + (mean(x)^2)/(ssx))^0.5*sigma  #Standard Error of Beta 0 (the linear regression parameters)
seBeta1 <-  sigma/sqrt(ssx)
#T statistic calculation from Student
tBeta0 <- beta0/seBeta0
tBeta1 <- beta1/seBeta1
#P-values of the regression linear line coefficients (Bo and B1)
pBeta0 <- 2*pt(abs(tBeta0),df=n-2,lower.tail=FALSE)     # multiplied by two since its the two sided test
pBeta1 <- 2*pt(abs(tBeta1),df=n-2,lower.tail=FALSE)
#place all metrics into a well formatted data.frame
coefTable <- rbind(c(beta0,seBeta0,tBeta0,pBeta0),c(beta1,seBeta1,tBeta1,pBeta1))
colnames(coefTable) <- c("Estimate","Std. Error","t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)","x")
#calculate coefficients using lm function
fit <- lm(y~x)
#confidence interval
sumCoef <- summary(fit)$coefficients
confIntBeta0 <- sumCoef[1,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
ConfIntBeta1 <- (sumCoef[2,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2])/10
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
#g
gg <- ggplotly(g)
devtools::install_github('hadley/ggplot2')
install.packages('devtools')
library(devtools)
devtools::install_github('hadley/ggplot2')
devtools::install_github('hadley/ggplot2')
library(UsingR)
library(plotly)
data(diamond)
y <- diamond$price
x <- diamond$carat
n <- length(x)
beta1 <- cor(y,x)*sd(y)/sd(x)
beta0 <- mean(y) - beta1*mean(x)
e <- y - (beta0 + beta1*x)           #remember that the residuals are the estimates
#of the errors introduced in the model
sigma <- sqrt(sum(e^2)/(n-2))
ssx <- sum((x-mean(x))^2)
#Standard Error calculation for each of the coefficients in preparation for T statistic
seBeta0 <- (1/n + (mean(x)^2)/(ssx))^0.5*sigma  #Standard Error of Beta 0 (the linear regression parameters)
seBeta1 <-  sigma/sqrt(ssx)
#T statistic calculation from Student
tBeta0 <- beta0/seBeta0
tBeta1 <- beta1/seBeta1
#P-values of the regression linear line coefficients (Bo and B1)
pBeta0 <- 2*pt(abs(tBeta0),df=n-2,lower.tail=FALSE)     # multiplied by two since its the two sided test
pBeta1 <- 2*pt(abs(tBeta1),df=n-2,lower.tail=FALSE)
#place all metrics into a well formatted data.frame
coefTable <- rbind(c(beta0,seBeta0,tBeta0,pBeta0),c(beta1,seBeta1,tBeta1,pBeta1))
colnames(coefTable) <- c("Estimate","Std. Error","t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)","x")
#calculate coefficients using lm function
fit <- lm(y~x)
#confidence interval
sumCoef <- summary(fit)$coefficients
confIntBeta0 <- sumCoef[1,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
ConfIntBeta1 <- (sumCoef[2,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2])/10
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
#g
gg <- ggplotly(g)
library(UsingR)
library(plotly)
data(diamond)
y <- diamond$price
x <- diamond$carat
n <- length(x)
beta1 <- cor(y,x)*sd(y)/sd(x)
beta0 <- mean(y) - beta1*mean(x)
e <- y - (beta0 + beta1*x)           #remember that the residuals are the estimates
#of the errors introduced in the model
sigma <- sqrt(sum(e^2)/(n-2))
ssx <- sum((x-mean(x))^2)
#Standard Error calculation for each of the coefficients in preparation for T statistic
seBeta0 <- (1/n + (mean(x)^2)/(ssx))^0.5*sigma  #Standard Error of Beta 0 (the linear regression parameters)
seBeta1 <-  sigma/sqrt(ssx)
#T statistic calculation from Student
tBeta0 <- beta0/seBeta0
tBeta1 <- beta1/seBeta1
#P-values of the regression linear line coefficients (Bo and B1)
pBeta0 <- 2*pt(abs(tBeta0),df=n-2,lower.tail=FALSE)     # multiplied by two since its the two sided test
pBeta1 <- 2*pt(abs(tBeta1),df=n-2,lower.tail=FALSE)
#place all metrics into a well formatted data.frame
coefTable <- rbind(c(beta0,seBeta0,tBeta0,pBeta0),c(beta1,seBeta1,tBeta1,pBeta1))
colnames(coefTable) <- c("Estimate","Std. Error","t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)","x")
#calculate coefficients using lm function
fit <- lm(y~x)
#confidence interval
sumCoef <- summary(fit)$coefficients
confIntBeta0 <- sumCoef[1,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
ConfIntBeta1 <- (sumCoef[2,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2])/10
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
#g
gg <- ggplotly(g)
library(ggplot2)
library(UsingR)
library(plotly)
data(diamond)
y <- diamond$price
x <- diamond$carat
n <- length(x)
beta1 <- cor(y,x)*sd(y)/sd(x)
beta0 <- mean(y) - beta1*mean(x)
e <- y - (beta0 + beta1*x)           #remember that the residuals are the estimates
#of the errors introduced in the model
sigma <- sqrt(sum(e^2)/(n-2))
ssx <- sum((x-mean(x))^2)
#Standard Error calculation for each of the coefficients in preparation for T statistic
seBeta0 <- (1/n + (mean(x)^2)/(ssx))^0.5*sigma  #Standard Error of Beta 0 (the linear regression parameters)
seBeta1 <-  sigma/sqrt(ssx)
#T statistic calculation from Student
tBeta0 <- beta0/seBeta0
tBeta1 <- beta1/seBeta1
#P-values of the regression linear line coefficients (Bo and B1)
pBeta0 <- 2*pt(abs(tBeta0),df=n-2,lower.tail=FALSE)     # multiplied by two since its the two sided test
pBeta1 <- 2*pt(abs(tBeta1),df=n-2,lower.tail=FALSE)
#place all metrics into a well formatted data.frame
coefTable <- rbind(c(beta0,seBeta0,tBeta0,pBeta0),c(beta1,seBeta1,tBeta1,pBeta1))
colnames(coefTable) <- c("Estimate","Std. Error","t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)","x")
#calculate coefficients using lm function
fit <- lm(y~x)
#confidence interval
sumCoef <- summary(fit)$coefficients
confIntBeta0 <- sumCoef[1,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
ConfIntBeta1 <- (sumCoef[2,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2])/10
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
#g
gg <- ggplotly(g)
install.packages(ggplot2)
install.packages('ggplot2')
install.packages("ggplot2")
library(UsingR)
library(plotly)
data(diamond)
y <- diamond$price
x <- diamond$carat
n <- length(x)
beta1 <- cor(y,x)*sd(y)/sd(x)
beta0 <- mean(y) - beta1*mean(x)
e <- y - (beta0 + beta1*x)           #remember that the residuals are the estimates
#of the errors introduced in the model
sigma <- sqrt(sum(e^2)/(n-2))
ssx <- sum((x-mean(x))^2)
#Standard Error calculation for each of the coefficients in preparation for T statistic
seBeta0 <- (1/n + (mean(x)^2)/(ssx))^0.5*sigma  #Standard Error of Beta 0 (the linear regression parameters)
seBeta1 <-  sigma/sqrt(ssx)
#T statistic calculation from Student
tBeta0 <- beta0/seBeta0
tBeta1 <- beta1/seBeta1
#P-values of the regression linear line coefficients (Bo and B1)
pBeta0 <- 2*pt(abs(tBeta0),df=n-2,lower.tail=FALSE)     # multiplied by two since its the two sided test
pBeta1 <- 2*pt(abs(tBeta1),df=n-2,lower.tail=FALSE)
#place all metrics into a well formatted data.frame
coefTable <- rbind(c(beta0,seBeta0,tBeta0,pBeta0),c(beta1,seBeta1,tBeta1,pBeta1))
colnames(coefTable) <- c("Estimate","Std. Error","t value", "P(>|t|)")
rownames(coefTable) <- c("(Intercept)","x")
#calculate coefficients using lm function
fit <- lm(y~x)
#confidence interval
sumCoef <- summary(fit)$coefficients
confIntBeta0 <- sumCoef[1,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[1,2]
ConfIntBeta1 <- (sumCoef[2,1] + c(-1,1)*qt(0.975,df=fit$df)*sumCoef[2,2])/10
library(ggplot2)
newx = data.frame(x = seq(min(x), max(x), length = 100))
p1 = data.frame(predict(fit, newdata= newx,interval = ("confidence")))
p2 = data.frame(predict(fit, newdata = newx,interval = ("prediction")))
p1$interval = "confidence"
p2$interval = "prediction"
p1$x = newx$x
p2$x = newx$x
dat = rbind(p1, p2)
names(dat)[1] = "y"
g = ggplot(dat, aes(x = x, y = y))
g = g + geom_ribbon(aes(ymin = lwr, ymax = upr, fill = interval), alpha = 0.2)
g = g + geom_line()
g = g + geom_point(data = data.frame(x = x, y=y), aes(x = x, y = y), size = 4)
#g
gg <- ggplotly(g)
library(devtools)
devtools::install_github('hadley/ggplot2')
getwd()
library(slidify)
setwd("C:/Users/Family/Documents/Data Science Specialisation/DataProducts/Shiny App Pitch")
getwd
getwd(())
library(yaml)
library(slidify)
library(slidifyLibraries)
slidify(index.Rmd)
getwd()
getwd()
setwd("C:/Users/Family/Documents/Data Science Specialisation/DataProducts/Shiny App Pitch/")
slidify(index.Rmd)
slidify("index.Rmd")
install.packages("yaml")
install.packages("yaml")
install.packages("yaml",force)
install.packages("yaml", force)
shiny::runApp('~/Rstudio Work/DataProducts/Quiz_q3')
getwd()
slidify("index.Rmd")
library(devtools)
library(UsingR)
slidify('index.Rmd')
library(devtools)
library(yaml)
library(slidify)
